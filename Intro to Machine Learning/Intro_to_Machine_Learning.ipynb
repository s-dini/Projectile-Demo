{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3CJbGkZHk1u"
   },
   "source": [
    "# Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPKXmWMaHnDR"
   },
   "source": [
    "\n",
    "- Students will understand the importance of ML, be able to verbally articulate that importance of, and discuss ways in which ML applies to everyday life.\n",
    "- Students will be able to explain the role of data in ML, as well as the difference between training, validating, and testing data\n",
    "-  Students will be able to identify errors in example machine learning code when prompted that there is an error.\n",
    "- Students will be able to argue why the Train/Val/Test split is important.\n",
    "- Students will be able to modify existing ML code to perform hyperparameter tuning when such code is clearly explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIZIlg3nSLYf"
   },
   "source": [
    "# Important Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCHNi7KiSb8O"
   },
   "source": [
    "The nice thing about google colab- other than the free computer hardware- is that it comes with a lot of very useful libraries for machine learning already installed. Let's take a look at some of the most important ones now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4wH_MroWiv8"
   },
   "source": [
    "\n",
    "\n",
    "> **Numpy**:Numpy is a Python library that handles the creation and manipulation of large datasets through the use of array-like data structures. It is the foundation for a lot of the other libraries we are about to discuss.\n",
    "\n",
    "> **Matplotlib**: This is a very popular visualization and plotting tool. Pretty much any plot you see done of machine learning content is probably done through Matplotlib.\n",
    "\n",
    ">**Scipy**: Scipy is another foundational tool with many useful functions for data analysis. It is especially useful for image processing tasks.\n",
    "\n",
    ">**Scikit-learn**: This library pulls together Scipy, Numpy, and Matplotlib to provide implementations for many popular classical machine learning algorithms.\n",
    "\n",
    ">**Pandas**: Pandas is another higher-level library that leverages Scipy, Numpy, and Matplotlib to perform data analysis and manipulation. If you are trying to inspect your dataset, pandas probably have whatever you're looking for through its DataFrame class.\n",
    "\n",
    ">**Tensorflow and Pytorch**: Tensorflow and pytorch are the predominant, easy-to-use interfaces for machine learning. In particular, these libraries are foundational to modern deep learning, which we will be getting into later.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpdxusSQSgKk"
   },
   "source": [
    "# But wait, why do we even need ML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCznyNHqSzJ5"
   },
   "source": [
    "\n",
    "That's a good question, and it's one we have yet to answer. The short version is that some problems are too complex for us to solve manually. Machine learning is a way for us to search for the most optimal solution for a problem.\n",
    "\n",
    "Let's imagine a simple problem: Suppose that I want you to figure out a student's GPA based on their exam scores. That shouldn't be too hard, right? Scores in your classes relate exactly to your GPA; there is a mathematical function that the school uses to take your scores and turn them into a GPA. Given some time (and maybe access to Google), we should be able to figure out the function that takes us from our input exam scores to our output.\n",
    "\n",
    "Now, let's complicate the problem. Say that I want to know students' GPA, but I don't have their test scores. Instead, I only have information about their average amount of sleep per night. Does the amount of sleep you get correlate to your grades? Yes, probably. But, it isn't a hard-and-fast rule like the relationship between exam scores and GPA. The situation is more complicated.\n",
    "\n",
    "If I sat down and spent all day trying to come up with some formula to model this relationship, I *might* be able to come up with something halfway decent. Now, let's consider the situation where I have more input. Let's say I have an average number of hours of sleep, information about parental involvement in the student's learning, what school they attend, which classes they take, if they take AP/IB classes, and how many extracurricular activities they participate in. That's *a lot* more variables to consider, and the chances that any human can sit down and come up with a function that relates all those inputs to a student's GPA with any sort of accuracy is much more slim. In situations like this, we employ machine learning.\n",
    "\n",
    "Machine learning is used when a problem becomes too complex for us to manually solve. Instead of coming up with a function ourselves, we develop clever algorithms that can figure out an optimal function for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2CzIblg9X1S"
   },
   "source": [
    "# Now let's do something cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3VI-Uze9cEd"
   },
   "source": [
    "You now have a sense of why machine learning is important, and are familiar, in passing, with the most popular machine learning libraries. Now, it's time to use them.\n",
    "\n",
    "You have probably seen the movie *Titanic*. If you haven't seen it, you've probably heard of it. If you haven't heard of it... Well... look it up I guess. The Titanic is, of course, based on the real-life shipwreck of the Titanic. In this exercise, we are going to use machine learning to predict whether passengers aboard the Titanic survived using information about their age, gender, wealth, etc (Credits to Kaggle for the dataset we are going to use).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "e9mrehlXP2l8",
    "outputId": "6b6408fe-465f-4414-f23b-c40e73ff008e"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(\"titanic.csv\") # populating dataframe \n",
    "raw_data.head()\n",
    "\n",
    "raw_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSJx8-rpGNQL"
   },
   "source": [
    "Let's dig into what that code did. First, we imported the Python module \"pandas\". As we talked about earlier, pandas is a module that is really good for analyzing and manipulating data. The whole \"import pandas *as pd*\" business is just creating an alias \"pd\" for the module \"pandas\". You are renaming pandas to be pd in your application.\n",
    "\n",
    "Then, we ran pd.read_csv. This function takes all the data from your file and loads it into the raw_data variable.\n",
    "\n",
    "Lastly, .head() is a function that acts on the data inside the raw_data variable. It just prints out the first few rows of data in a format that's easy to look at.\n",
    "\n",
    "Let's take a second to inspect the raw_data variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qNxMvnR3H4bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWYgs1jfH7nV"
   },
   "source": [
    "The above line of code will tell you what type of object the variable raw_data is. Running the code, you will see that raw_data is a Dataframe object. Dataframes are a custom object provided by pandas that is very useful for data analysis.\n",
    "\n",
    "Now, if you take a closer look at the data above, you might notice some problems with it. Some columns have a categorical label (such as survived), some have a numerical value (such as age), and others have a string value (like name). Additionally, in some columns, you may have noticed a value of \"NaN\". The value of NaN can be returned based on different errors in the original data, one of which is missing data. When working with machine learning, these types of data have to be treated differently. Two common approaches to dealing with this are to get rid of any entry that has a NaN, or to interpolate the average value from the existing data to replace the Nan. Be careful with this dataset, because some of the columns, such as Age, do have Nans.\n",
    "\n",
    "Additionally, it is usually important to think about what parts of your data are important before you apply any sort of machine learning algorithm. This process is called \"Feature Engineering\". For deep learning, this process is not as important, as deep learning automates feature extraction. However, for any shallow learning algorithms, feature engineering is a must.\n",
    "\n",
    "In this application, we will skip ahead a bit. Instead of thoroughly investigating each variable and determining which ones correlate with the output most thoroughly, we will just use \"Sex\" and \"Pclass\", since, from the story of The Titanic, we know that sex and income correlate well with survival rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fzNZPGQk69D0"
   },
   "outputs": [],
   "source": [
    "raw_data.drop([\"PassengerId\", \"Cabin\", \"Embarked\",\n",
    "               \"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\"], axis = 1, inplace = True)\n",
    "\n",
    "# inplace = permanent change \n",
    "# axis = y ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8-ibKSn-DCI"
   },
   "source": [
    "Great, we have dropped all the rows of data that we don't want. Let's look at what we have again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EH1yh4lX-CiM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex\n",
       "0         0       3    male\n",
       "1         1       1  female\n",
       "2         1       3  female\n",
       "3         1       1  female\n",
       "4         0       3    male"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tDFBjdZ-mp4"
   },
   "source": [
    "I mentioned earlier that computers can't operate on strings (words) such as \"male\" and \"female\". We must assign numbers as labels (0 or 1) instead of the string label currently in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-EN4opukpXdj"
   },
   "outputs": [],
   "source": [
    "import numpy as np #so we can use the \"where\" function.\n",
    "raw_data['Sex'] = np.where(raw_data['Sex'] == 'male', 0, raw_data['Sex'])# read this like \"where raw_data['Sex'] = male\n",
    "#replace 'male' with 0. Otherwise, just use the value in raw_data['Sex'].\n",
    "raw_data['Sex'] = np.where(raw_data['Sex'] == 'female', 1, raw_data['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2lcIpH5tKPG"
   },
   "source": [
    "Now, it's time to split up the data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hszaGXLHP3UO"
   },
   "source": [
    "## Training, Validating, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hham8RzcP_65"
   },
   "source": [
    "All machine learning tasks need a training, validation, and testing dataset. To get these, you take your raw data and simply split it into three parts. Commonly, 80% of your raw data becomes the training dataset, 10% becomes your validation set, and the last 10% becomes your testing dataset.\n",
    "\n",
    "The reason for the training and testing sets should be fairly intuitive. Think about what you do in school: you learn new information from your teachers, the textbook, the internet, etc. Then, you are given a final exam to see how well you learned that new information. The questions on the exam are *similar* to what you learned from, but they are not the exact same. In the same way, we need to give the algorithm data to learn from, and separate but similar data to test itself on.\n",
    "\n",
    "The reason for a validation set, however, might not be as clear. Validation sets and Testing sets are really similar; they are both datasets used as an evaluation tool for your algorithm. The key difference is that testing datasets are used *at the end* of the training process as the final check that your algorithm is working as you want it to, and validation is used to check incrementally during training. To continue our school analogy, if the training dataset is like the information in your textbook that you learn from, and the testing dataset is like the questions on your final exam, then the validation dataset is like the quizzes during the school year. Fundamentally, they are no different than the questions on the final exam, but they are *used* differently.\n",
    "\n",
    "You might be thinking, \"Why in the world does a machine learning model have to have quizzes and a final exam? This feels weird and redundant\". That's a valid criticism because it seems like a model should be able to just learn with a test dataset \"final exam\". We will take an in-depth look into the function of the validation dataset in a later module, but I want to at least give a quick sneak peek into the rationale here so you aren't left befuddled. The reason we have all three datasets has to do with two keywords you will see pop up time and time again: **overfitting** and **hyperparameter tuning**.\n",
    "\n",
    "Overfitting basically means that your model has memorized the training dataset, but not the underlying patterns. It's like if you sat down and memorized a bunch of example problems from your math book, but never actually took the time to understand what was happening. What happens when it comes to quiz time? You fail because you never learned how to actually do the problem, *you just memorized the examples you were given*. The same thing can happen to a machine learning model, and giving it \"quizzes\" along the way can help us catch when the model isn't actually learning, but is just memorizing the training dataset. When it gets to the validation dataset, we can see it fail and make adjustments.\n",
    "\n",
    "How do we make adjustments? That's where hyperparameter tuning comes in. Hyperparameters are variables you can change to modify the way in which a machine learning network behaves. However, it is possible to overtune the model to perform well on the validation dataset, which will again lead to overfitting. But this time, you won't be able to notice the overfitting because you have made it overfit to the validation dataset. This is where the test dataset comes into play; the test dataset makes sure *you yourself* didn't cause the model to overfit.\n",
    "\n",
    "To make an analogy, imagine that your machine learning model is a physical machine -- perhaps a racecar. Hyperparameters are the things you can tweak and tune to make your model -- your racecar -- work better. You can tweak things like engine torque, wheel size, and chassis shape to try to make the car run better on a given track.\n",
    "\n",
    "Let's say you are a racecar engineer. You design a car and you run simulations and such to make sure your car will work, based on data from previous cars built. This is like training your model on the training dataset. Then, you build a prototype racecar, bring it to the track, and test it. After testing, you realize you could change some things to make it run better -- analysis shows that increasing engine torque would make it run better on the track because the track is really hilly. So, you go back and tweak your design to have higher torque. This is like hyperparameter tuning. You do this process for a while, tweaking the torque until you are convinced you have the best racecar possible. You ship it to production and it goes out to the world. But soon, you get complaints from customers saying that your racecar is being outrun by most other racecars on all tracks that aren't hilly! Why did this happen? You overturned you racecar design for specifically hilly tracks when it needed to perform on all types of tracks. So, when the racecar performs on anything other than its track (the track it was validated on), it performs poorly. If only we had tested on other racetracks before shipping to production!\n",
    "\n",
    "This is, in essence, what can happen to machine learning models when you do hyperparameter tuning. If you tune your racecar -- your ML model -- to perform really well on one track (on a validation dataset), you run the risk of making it perform poorly on real racetracks (the data you use your model on in the real world). To safeguard against this, we use a testing dataset (other racetracks) to make sure that our model can perform on similar data that we didn't specifically tune to perform well on.\n",
    "\n",
    "So, now that we have covered why you need to split raw data into three sets, let's actually do it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5v2uqXcKMbQ_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data ,test_and_val_data = train_test_split(raw_data, test_size = .20, random_state = 2) #split into train and an aggragated test and val\n",
    "val_data, test_data = train_test_split(test_and_val_data, test_size = .50, random_state = 2)#split aggregagted into test and val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ETDWxv6U_sH"
   },
   "source": [
    "This code uses the library scikit-learn (which we talked about earlier) to split our raw data into train, test, and validation. Read about the train_test_split function [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "That link takes you to the published documentation on scikit-learn. All major libraries you use in machine learning (and anywhere else, really) will have documentation published on how their functions work, how you can use them, and (often) example code of it in use. The documentation (sometimes called an API) is your primary resource in figuring out how to use any function included in Python libraries.\n",
    "\n",
    "**OFTEN, LOOKING AT THE PUBLISHED DOCUMENTATION IS EASIER THAN JUST GOOGLING IT**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERzdkbEkW6PI"
   },
   "source": [
    "## Let's get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7YU0Ql0W_mG"
   },
   "source": [
    "Now, let's take our data and get to classifying. For this exercise, we are going to be using an algorithm called random forests. It's not super critical that you have a deep understanding of how the algorithm works. If you want to learn more, [here](https://www.analyticsvidhya.com/blog/2021/10/an-introduction-to-random-forest-algorithm-for-beginners/) is a good resource on random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvVDtESn5lc2"
   },
   "source": [
    "First, we split the test data into input and output. \"Y\" is our labels for who survived. \"X\" are our input variables: Purchasing class and sex. Then, we make a Random Forest Model with 10 trees in our forest, and a max_depth of 5 on each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "orP4R7mdt8Fn"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Y = train_data['Survived']\n",
    "X = train_data[['Pclass', 'Sex']]\n",
    "model = RandomForestClassifier(10, max_depth = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3jdSrEu7e3m"
   },
   "source": [
    "Next, we \"fit\" the model. This is where the algorithm actually does the learning. It is called \"fit\" because we are \"fitting\" the algorithm onto our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B3a4MaAuygMt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, n_estimators=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ9v03Wo757g"
   },
   "source": [
    "Now, we can evaluate how well our model works on our validation data. If you followed all the above instructions, your model should be about 75% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Eb1KMcOz0r5c"
   },
   "outputs": [],
   "source": [
    "val_Y = val_data['Survived']\n",
    "val_X = val_data[['Pclass', 'Sex']]\n",
    "predictions = model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7G-BG8VxzCny"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.28089887640449\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "accuracy = np.sum(val_Y == predictions)/len(val_X)*100\n",
    "print(\"Accuracy: \" , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86jqcYr586lO"
   },
   "source": [
    "# Now, make some changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kymxoleX8-hx"
   },
   "source": [
    "Congratulations! You have now trained your first machine learning model! Now, it's time to make it your own. I only specified the number of trees and the depth of the trees, but there are more hyperparameters you can tune. Look at the documentation, here at https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html. Make your own changes, experiment, and see if you can get better results.\n",
    "\n",
    "Then, it's time for a real challenge: you should try to include more rows of data. If you remember we dropped many rows of data earlier for the sake of simplicity. However, there is a lot of information embedded into that data, and a machine learning model is only as good as its data. More than likely, including more relevant data will lead to more improvements than hyperparameter tuning. Each type of data has its own issues. Some have missing data points (NaNs), which will cause the training to crash unless you either get rid of those data points or interpolate some value for the missing value. Some are categorical, others aren't. Categorical data are either number labels (e.g.: 1,2,3) or strings (words) that need to be converted to number labels. before you can use it. Pick one column of data that you think would be relevant to determining which people survived the Titanic and which ones didn't, and then try to incorporate it into the model.\n",
    "\n",
    "When you run into issues, ask yourself:\n",
    "\n",
    "1) Are there any NaN (missing values) in the data column I am using?\n",
    "\n",
    "2) Are there any strings (words) left in your data?\n",
    "\n",
    "You may run into other issues as well. Google is your friend here; when you get an error code, be sure to google that error code and try to figure out what it means. Then, once you understand what the error is telling you, try to find where the error is in your code.\n",
    "\n",
    "When you're done, evaluate your model against the testing dataset to get your final accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAZPLfIDa9Bp"
   },
   "source": [
    "To get you started, we will go ahead and copy all relevant code from above down so that you have it all in one place. **THERE IS NO NEED TO RUN ANY CODE FROM ABOVE THIS POINT DURING THIS EXERCISE**. Just make modifications to the code below.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5dZS6TcVFSu",
    "outputId": "8ade021e-4359-42a4-e42a-c424fb12f68c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy:  86.11111111111111\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the data file\n",
    "raw_data = pd.read_csv('titanic.csv')\n",
    "raw_data.head()\n",
    "\n",
    "type(raw_data)\n",
    "\n",
    "# drop columns we will not be using\n",
    "raw_data.drop([\"PassengerId\", \"Cabin\", \"Embarked\",\n",
    "               \"Name\", \"SibSp\", \"Parch\", \"Ticket\"], axis = 1, inplace = True)\n",
    "\n",
    "raw_data.head()\n",
    "\n",
    "\n",
    "# format the data\n",
    "import numpy as np #so we can use the \"where\" function.\n",
    "raw_data['Sex'] = np.where(raw_data['Sex'] == 'male', 0, raw_data['Sex'])# read this like \"where raw_data['Sex'] = male\n",
    "#replace 'male' with 0. Otherwise, just use the value in raw_data['Sex'].\n",
    "raw_data['Sex'] = np.where(raw_data['Sex'] == 'female', 1, raw_data['Sex'])\n",
    "\n",
    "raw_data.dropna(subset=['Age'], inplace=True)\n",
    "# raw_data = raw_data.interpolate(method='linear', axis=0).ffill()\n",
    "\n",
    "\n",
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data ,test_and_val_data = train_test_split(raw_data, test_size = .20, random_state = 2) #split into train and an aggragated test and val\n",
    "val_data, test_data = train_test_split(test_and_val_data, test_size = .50, random_state = 2)#split aggregagted into test and val\n",
    "\n",
    "# split data into input and output\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Y = train_data['Survived']\n",
    "X = train_data[['Sex']]\n",
    "model = RandomForestClassifier(100, max_depth = 5)\n",
    "\n",
    "# train the model\n",
    "model.fit(X,Y)\n",
    "\n",
    "# evaluate based on accuracy\n",
    "test_Y = test_data['Survived']\n",
    "test_X = test_data[['Sex']]\n",
    "predictions_test = model.predict(test_X)\n",
    "accuracy_test = np.sum(test_Y == predictions_test)/len(test_X)*100\n",
    "print(\"Final Accuracy: \" , accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UE1i8EOwAJf"
   },
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YswO5t5KwDIl"
   },
   "source": [
    "Authors: Caden Hamrick, JoHanna Rodenbeck, Louisa Houser, Shane Tharani"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
